{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_question_ids(dataframe):\n",
    "    return dataframe.original_question_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_id(dataframe, orgq_ids):\n",
    "    grouped_dict = dict()\n",
    "\n",
    "    for qid in orgq_ids:\n",
    "        grouped_dict[qid] = dataframe[dataframe.original_question_id == qid]\n",
    "\n",
    "    return grouped_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_grouped(group_dict):\n",
    "    irrelevant = []\n",
    "    mixed = []\n",
    "    \n",
    "    for qid, qdf in group_dict.items():\n",
    "        if len(qdf[qdf.relevance == 'Irrelevant']) == 50:\n",
    "            irrelevant.append(qdf)\n",
    "        else:\n",
    "            mixed.append(qdf)\n",
    "            \n",
    "    return irrelevant, mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrink_df(irrelevant_only, mixed, irrelevant_size=200, mixed_size=100, csv_path=None):\n",
    "    shrinked_irrelevant_only = irrelevant_only[:irrelevant_size//50]\n",
    "    shrinked_mixed = mixed[:mixed_size//50]\n",
    "    merged = shrinked_mixed + shrinked_irrelevant_only\n",
    "\n",
    "    print(\"Small dataset total size = {} rows\".format(len(merged) * 50))\n",
    "    print(\"Small mixed size = {} rows\".format(len(shrinked_mixed) * 50))\n",
    "    print(\"Small irrelevant only size = {} rows\".format(len(shrinked_irrelevant_only) * 50))\n",
    "\n",
    "    shrinked_df = merged[0]\n",
    "    for df in merged[1:]:\n",
    "        shrinked_df = shrinked_df.append(df)\n",
    "    \n",
    "    if csv_path is not None:\n",
    "        shrinked_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    return shrinked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_smaller_datasets(filepath, name=None, small_sizes=(200, 100), xsmall_sizes=(50, 50), base_dir='/Volumes/DataDrive/stripped'):\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError('{} has not been found.'.format(filepath))\n",
    "    \n",
    "    if name is None:\n",
    "        basename = os.path.basename(filepath)\n",
    "        name = os.path.splitext(basename)[0]\n",
    "        \n",
    "    print(\"Reading {}...\".format(filepath))\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(\"Done.\")\n",
    "    \n",
    "    unique_qids = get_unique_question_ids(df)\n",
    "    grouped = group_by_id(df, unique_qids)\n",
    "    irrelevant, mixed = split_grouped(grouped)\n",
    "    \n",
    "    # Small file\n",
    "    small_filepath = '{}/{}-small.csv'.format(base_dir, name)\n",
    "    irrelevant_size, mixed_size = small_sizes\n",
    "    shrink_df(irrelevant, mixed, irrelevant_size=irrelevant_size, mixed_size=mixed_size, csv_path=small_filepath)\n",
    "    \n",
    "    # X-Small file\n",
    "    xsmall_filepath = '{}/{}-xsmall.csv'.format(base_dir, name)\n",
    "    irrelevant_size, mixed_size = xsmall_sizes\n",
    "    shrink_df(irrelevant, mixed, irrelevant_size=irrelevant_size, mixed_size=mixed_size, csv_path=xsmall_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Volumes/DataDrive/stripped/english-train.csv...\n",
      "Done.\n",
      "Small dataset total size = 5000 rows\n",
      "Small mixed size = 3000 rows\n",
      "Small irrelevant only size = 2000 rows\n",
      "Small dataset total size = 600 rows\n",
      "Small mixed size = 500 rows\n",
      "Small irrelevant only size = 100 rows\n",
      "Reading /Volumes/DataDrive/stripped/english-devel.csv...\n",
      "Done.\n",
      "Small dataset total size = 1500 rows\n",
      "Small mixed size = 1000 rows\n",
      "Small irrelevant only size = 500 rows\n",
      "Small dataset total size = 250 rows\n",
      "Small mixed size = 200 rows\n",
      "Small irrelevant only size = 50 rows\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATASET = '/Volumes/DataDrive/stripped/english-train.csv'\n",
    "TEST_DATASET = '/Volumes/DataDrive/stripped/english-devel.csv'\n",
    "\n",
    "# Generate from \"train\" dataset\n",
    "generate_smaller_datasets(TRAIN_DATASET, name='english-train', small_sizes=(2000, 3000), xsmall_sizes=(100, 500))\n",
    "\n",
    "# Generate from \"test\" dataset\n",
    "generate_smaller_datasets(TEST_DATASET, name='english-devel', small_sizes=(500, 1000), xsmall_sizes=(50, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:eng]",
   "language": "python",
   "name": "conda-env-eng-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
